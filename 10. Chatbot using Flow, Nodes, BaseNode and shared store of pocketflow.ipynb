{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“¦ Imports & Environment Setup\n",
        "\n",
        "This cell imports everything required to run the chatbot.\n",
        "\n",
        "- `requests` is used to call the TypeGPT API.\n",
        "- `time`, `copy`, and `warnings` support flow execution and safety.\n",
        "- `typing` helps with clean function signatures.\n",
        "- `userdata` reads secrets securely from Google Colab (no hard-coded API keys).\n",
        "\n",
        "Nothing runs here yet. This cell only prepares the environment.\n"
      ],
      "metadata": {
        "id": "FO7PW8XoyTuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Imports =====\n",
        "import time\n",
        "import copy\n",
        "import warnings\n",
        "import requests\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from google.colab import userdata  # for secrets\n"
      ],
      "metadata": {
        "id": "mNm0VDmtnmwS"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”‘ TypeGPT API Configuration\n",
        "\n",
        "This cell handles all communication with the TypeGPT API.\n",
        "\n",
        "What happens here:\n",
        "- The API base URL is defined.\n",
        "- The API key is securely loaded from **Colab Secrets**.\n",
        "- `call_typegpt()` sends conversation messages to the model.\n",
        "- The function returns only the assistantâ€™s final text response.\n",
        "\n",
        "If the API fails, it raises an error so we can catch it later.\n"
      ],
      "metadata": {
        "id": "0jzAxY6DyVAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== TypeGPT API =====\n",
        "TYPEGPT_API_BASE = \"https://api.typegpt.net/v1\"\n",
        "TYPEGPT_API_KEY = userdata.get(\"TYPEGPT_API_KEY\")  # <-- stored in Colab Secrets\n",
        "\n",
        "def call_typegpt(messages: List[Dict[str, str]], model=\"openai/gpt-oss-20b\"):\n",
        "    url = f\"{TYPEGPT_API_BASE}/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {TYPEGPT_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\": 0.7,\n",
        "    }\n",
        "    res = requests.post(url, json=payload, headers=headers, timeout=30)\n",
        "    res.raise_for_status()\n",
        "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n"
      ],
      "metadata": {
        "id": "2ehzNrQ9uNt0"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ§  Minimal PocketFlow Engine\n",
        "\n",
        "This cell defines a tiny workflow engine inspired by PocketFlow.\n",
        "\n",
        "Key ideas:\n",
        "- Each **Node** performs one small task.\n",
        "- Nodes are connected using `then()` to form a loop.\n",
        "- The **Flow** object runs nodes one by one.\n",
        "- Execution continues until a node returns `None`.\n",
        "\n",
        "This keeps the chatbot logic modular and easy to extend.\n"
      ],
      "metadata": {
        "id": "3Tu5lQo6yXic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== PocketFlow Core =====\n",
        "class Node:\n",
        "    def __init__(self):\n",
        "        self.next_node = None\n",
        "\n",
        "    def then(self, node):\n",
        "        self.next_node = node\n",
        "        return node\n",
        "\n",
        "    def run(self, shared):\n",
        "        out = self.exec(shared)\n",
        "        return out\n",
        "\n",
        "    def exec(self, shared):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class Flow:\n",
        "    def __init__(self, start):\n",
        "        self.start = start\n",
        "\n",
        "    def run(self, shared):\n",
        "        curr = copy.copy(self.start)\n",
        "        while curr:\n",
        "            curr = curr.run(shared)\n"
      ],
      "metadata": {
        "id": "FR31KPNduP7c"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âŒ¨ï¸ Input Node\n",
        "\n",
        "This node:\n",
        "- Reads user input from the terminal.\n",
        "- Stops the chatbot if the user types `exit` or `quit`.\n",
        "- Stores the user message in shared memory.\n",
        "\n",
        "This is the entry point of every chatbot turn.\n"
      ],
      "metadata": {
        "id": "b9Wi-0dfyZYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputNode(Node):\n",
        "    def exec(self, shared):\n",
        "        text = input(\"You: \").strip()\n",
        "        if text.lower() in (\"exit\", \"quit\"):\n",
        "            return None\n",
        "        shared[\"last_user\"] = text\n",
        "        return self.next_node\n"
      ],
      "metadata": {
        "id": "O3X6hS0EuT-T"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ—ƒï¸ Memory Node\n",
        "\n",
        "This node:\n",
        "- Maintains the full conversation history.\n",
        "- Appends each user message to the shared `store`.\n",
        "- Uses OpenAI-style message format (`role`, `content`).\n",
        "\n",
        "This stored history is later sent to the LLM.\n"
      ],
      "metadata": {
        "id": "fyZ2GvGSybMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryNode(Node):\n",
        "    def exec(self, shared):\n",
        "        store = shared.setdefault(\"store\", [])\n",
        "        store.append({\"role\": \"user\", \"content\": shared[\"last_user\"]})\n",
        "        return self.next_node\n"
      ],
      "metadata": {
        "id": "q7NgwoycvajP"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ¤– API Node (LLM Call)\n",
        "\n",
        "This node:\n",
        "- Sends the full conversation history to TypeGPT.\n",
        "- Receives the assistantâ€™s response.\n",
        "- Handles API errors gracefully.\n",
        "- Stores the assistant reply back into memory.\n",
        "\n",
        "This is where the actual intelligence happens.\n"
      ],
      "metadata": {
        "id": "azDEsyuAydAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class APINode(Node):\n",
        "    def exec(self, shared):\n",
        "        try:\n",
        "            reply = call_typegpt(shared[\"store\"])\n",
        "        except Exception as e:\n",
        "            reply = f\"[API error] {e}\"\n",
        "        shared[\"store\"].append({\"role\": \"assistant\", \"content\": reply})\n",
        "        shared[\"last_assistant\"] = reply\n",
        "        return self.next_node\n"
      ],
      "metadata": {
        "id": "YFSEFFUqvb48"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ–¥ï¸ Display Node\n",
        "\n",
        "This node:\n",
        "- Prints the assistantâ€™s response clearly to the console.\n",
        "- Acts as the final step before looping back to input.\n",
        "\n",
        "After displaying the message, control returns to the InputNode.\n"
      ],
      "metadata": {
        "id": "ghqVZr3jygOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayNode(Node):\n",
        "    def exec(self, shared):\n",
        "        print(\"\\nAssistant:\", shared[\"last_assistant\"], \"\\n\")\n",
        "        return self.next_node\n"
      ],
      "metadata": {
        "id": "HnFi4C-qvc-G"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”— Wiring the Chatbot Flow\n",
        "\n",
        "This cell connects all nodes into a loop:\n",
        "\n",
        "Input â†’ Memory â†’ API â†’ Display â†’ Input\n",
        "\n",
        "Each message follows this exact path.\n",
        "The loop continues until the user exits.\n"
      ],
      "metadata": {
        "id": "Z-yWEbJwyhph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Build Flow =====\n",
        "input_node = InputNode()\n",
        "memory_node = MemoryNode()\n",
        "api_node = APINode()\n",
        "display_node = DisplayNode()\n",
        "\n",
        "input_node.then(memory_node)\\\n",
        "          .then(api_node)\\\n",
        "          .then(display_node)\\\n",
        "          .then(input_node)\n",
        "\n",
        "flow = Flow(input_node)\n"
      ],
      "metadata": {
        "id": "wnlxREfvvd7q"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶ï¸ Run the Chatbot\n",
        "\n",
        "This cell:\n",
        "- Initializes shared memory.\n",
        "- Adds a system prompt to guide behavior.\n",
        "- Starts the flow execution.\n",
        "\n",
        "Once this cell runs, the chatbot stays active until `exit` is typed.\n"
      ],
      "metadata": {
        "id": "3wofPX7byj9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Run =====\n",
        "shared = {\"store\": [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer concisely.\"}\n",
        "]}\n",
        "\n",
        "print(\"Chatbot ready. Type 'exit' to stop.\\n\")\n",
        "flow.run(shared)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGCchcZPxXR5",
        "outputId": "0a1c9af4-11b1-4568-cba5-20b60f177bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot ready. Type 'exit' to stop.\n",
            "\n",
            "You: hi\n",
            "\n",
            "Assistant: Hello! ðŸ‘‹ How can I help you today? \n",
            "\n",
            "You: what is pockeflow?\n",
            "\n",
            "Assistant: [API error] HTTPSConnectionPool(host='api.typegpt.net', port=443): Read timed out. (read timeout=30) \n",
            "\n",
            "You: hi\n",
            "\n",
            "Assistant: Hi there! ðŸ‘‹ How can I help you today? \n",
            "\n",
            "You: who ru?\n",
            "\n",
            "Assistant: Iâ€™m ChatGPT, a large language model created by OpenAI. Iâ€™m here to answer questions, help with writing, brainstorm ideas, explain concepts, and chat about almost anything youâ€™re curious about. Just let me know what you need! \n",
            "\n",
            "You: What is pocket flow?\n",
            "\n",
            "Assistant: **Pocket Flow** can mean a few different things depending on the field youâ€™re looking at. Below are the most common uses of the term:\n",
            "\n",
            "| Context | What it is | Typical use |\n",
            "|---------|------------|-------------|\n",
            "| **Portable waterâ€‘flow meter** | A small, handâ€‘held device (often called a â€œpocketâ€‘sizeâ€ flow meter) that measures flow rate, pressure, and temperature in pipes. | Leak detection, waterâ€‘use monitoring, utility audits, field testing by plumbers or engineers. |\n",
            "| **Microfluidics / Labâ€‘onâ€‘aâ€‘chip** | â€œPocket flowâ€ refers to the movement of fluid in a tiny pocket or cavity inside a microfluidic channel. Itâ€™s often used for mixing, reaction control, or sample handling. | Research, diagnostics, chemical synthesis, pointâ€‘ofâ€‘care testing. |\n",
            "| **Portable bloodâ€‘flow monitor** | A handheld Doppler or ultrasound device that can be carried in a pocket and used to assess blood flow in peripheral arteries. | Clinical screening for peripheral artery disease, sports medicine, occupational health. |\n",
            "| **Software / Dataâ€‘flow concept** | In some dataâ€‘engineering contexts, â€œpocket flowâ€ can refer to a lightweight, onâ€‘theâ€‘go dataâ€‘flow pipeline that runs in a small, isolated â€œpocketâ€ of a larger system. | Edge computing, IoT analytics, microâ€‘services orchestration. |\n",
            "\n",
            "If you had a particular industry or application in mind, let me know and I can dive deeper into that specific meaning! \n",
            "\n"
          ]
        }
      ]
    }
  ]
}